\documentclass[../main.tex]{subfiles}

\begin{document}
\begin{algorithm}
    \caption{DQN Learning- Gradient Learning}\label{alg:dqn}
    \begin{algorithmic}
    \State Initialise a Q network  with parameters $\theta$
    \State start with state $s_t$
    \While{True}
    \State take action $a_t$ 
    \State observe next state $s_{t+1}$ and $R_{t+1}$
    \State calculate the gradient $$ \theta \leftarrow \theta + \alpha \bigtriangledown_\theta \left[ R_{t+1} + \gamma \textit{max}_{a} Q_\theta(s_{t+1}, a ) - Q_\theta(s_t, a_t) \right]$$
    \State $s_t \leftarrow s_{t+1}$
    \EndWhile
    \end{algorithmic}
    \end{algorithm}
    
    
    \begin{algorithm}
    \caption{DQN Learning- Experience Replay Learning}\label{alg:dqn_ex_replay}
    \begin{algorithmic}
    \State Initialise a Q network  with parameters $\theta$
    \State start with state $s_t$
    \State Initialise a replay buffer $D$
    \While{True}
    \State take action $a_t$ 
    \State observe next state $s_{t+1}$ and $R_{t+1}$
    \State save the transition $(s_t, a_t, R_{t+1}, s_{t+1})$ in $D$
    \While{some epochs}
    \State sample a mini-batch $N$ from the replay buffer $D$
    \State calculate the gradient $$ \theta \leftarrow \theta + \alpha \bigtriangledown_\theta \frac{1}{N}\sum\limits_{i=1}^N \left[ R_{t+1}^i + \gamma \textit{max}_{a^i} Q_\theta(s_{t+1}^i, a^i ) - Q_\theta(s_t^i, a_t^i) \right]$$
    \EndWhile
    \State $s_t \leftarrow s_{t+1}$
    \EndWhile
    \end{algorithmic}
    \end{algorithm}
    
    
    
    \begin{algorithm}
    \caption{DQN Learning- Experience Replay Learning with Target network}\label{alg:dqn_ex_replay_with_target}
    \begin{algorithmic}
    \State Initialise a Q network  with parameters $\theta$ and Target $Q$ network with parameters $\theta'$
    \State $\theta' \leftarrow \theta$
    \State start with state $s_t$
    \State Initialise a replay buffer $D$
    \While{True}
    \State take action $a_t$ 
    \State observe next state $s_{t+1}$ and $R_{t+1}$
    \State save the transition $(s_t, a_t, R_{t+1}, s_{t+1})$ in $D$
    \While{some epochs}
    \State sample a mini-batch $N$ from the replay buffer $D$
    \State calculate the gradient $$ \theta \leftarrow \theta + \alpha \bigtriangledown_\theta \frac{1}{N}\sum\limits_{i=1}^N \left[ R_{t+1}^i + \gamma \textit{max}_{a^i} Q_{\theta'}(s_{t+1}^i, a^i ) - Q_\theta(s_t^i, a_t^i) \right]$$
    \EndWhile
    \State $\theta' \leftarrow \theta$
    \State $s_t \leftarrow s_{t+1}$
    \EndWhile
    \end{algorithmic}
    \end{algorithm}
    
    \newpage
    

\end{document}